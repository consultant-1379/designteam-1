server.port=9887

db.repdb.url=jdbc:sybase:Tds:10.36.255.71:2641
#db.repdb.url=jdbc:postgresql://10.45.193.129:30007/postgres
db.dwhdb.url=jdbc:sybase:Tds:10.36.255.71:2640
db.dwhdb.driver=com.sybase.jdbc4.jdbc.SybDriver
db.repdb.driver=com.sybase.jdbc4.jdbc.SybDriver
#db.repdb.driver=org.postgresql.Driver
db.repdb.etlrep.user=etlrep
db.repdb.etlrep.pass=etlrep
db.repdb.dwhrep.user=dwhrep
db.repdb.dwhrep.pass=dwhrep
db.dwhdb.user=dc
db.dwhdb.pass=Dc12#
parser.type=eniqasn1
#Dc12#
parser.batch.size=5


#kafka properties
spring.kafka.bootstrap-servers=10.45.193.129:31166
spring.kafka.consumer.topic=PM_E_BSS_FILES
#spring.kafka.consumer.topic=ASN1TOPIC
spring.kafka.consumer.group-id=PM_E_BSS_FILES_GROUP
#spring.kafka.consumer.group-id=asn1group 
#spring.kafka.producer.group-id=PM_E_BSS_DATA_GROUP 
spring.kafka.consumer.max-poll-records=5
spring.kafka.consumer.enable-auto-commit=false
spring.kafka.consumer.auto-offset-reset=latest
spring.kafka.listener.ack-mode=MANUAL_IMMEDIATE


#consumer.id=ASN1PARSER

#tp.list=DC_E_BSS,DC_E_CPP
tp.list=DC_E_BSS


producer.topic=PM_E_BSS_DATA

#spring.cloud.stream.default.producer.useNativeEncoding=true
#spring.cloud.stream.default.bindings.output.destination=mdcout
#spring.cloud.stream.default.bindings.output.content-type=application/*+avro
#spring.cloud.stream.kafka.binder.producer-properties.key.serializer=io.confluent.kafka.serializers.KafkaAvroSerializer
#spring.cloud.stream.kafka.binder.producer-properties.value.serializer=io.confluent.kafka.serializers.KafkaAvroSerializer
#spring.cloud.stream.kafka.binder.producer-properties.schema.registry.url=http://10.45.193.129:32015

#schema.registry.url=http://10.45.193.129:31155
schema.registry.url=http://10.45.193.129:32015


#management.endpoints.web.exposure.include=info, health, prometheus, loggers
#management.endpoints.web.basepath=/
#management.endpoints.web.path-mappings.prometheus=metrics
#management.endpoints.prometheus.enabled=true
#management.endpoints.metrics.export.prometheus.enabled=true
#management.server.port=7878


